{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDClassifier, Lasso,RidgeCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve, KFold\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, median_absolute_error, mean_absolute_percentage_error, RocCurveDisplay, mean_squared_log_error,  accuracy_score,precision_score,recall_score,f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, RobustScaler, StandardScaler, FunctionTransformer, LabelEncoder, OneHotEncoder, Binarizer, OrdinalEncoder, MaxAbsScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, RFE, RFECV \n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor, ExtraTreesRegressor, VotingClassifier, VotingRegressor,StackingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# from pycaret.regression import *\n",
    "import xgboost\n",
    "from os import stat\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from contextlib import closing\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from datetime import datetime \n",
    "import lightgbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle : \n",
    "\n",
    "https://www.kaggle.com/c/bike-sharing-demand/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions run_df avec pandas\n",
    "\n",
    "# # Data pour Lille à voir si utilisable  \n",
    "# # https://opendata.lillemetropole.fr/explore/dataset/vlille-realtime/table/\n",
    "\n",
    "# # Skip logs about pandas caveats documentations \n",
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "\n",
    "# # Pipeline pour la prédiction personnalisée : \n",
    "\n",
    "# def run_df_dc_personalised(df, date, time, weather, temp, temp_feel, humidity, windspeed):\n",
    "    \n",
    "#     # Day of year \n",
    "#     # print(time[0:2])\n",
    "    \n",
    "#     df.iloc[0:1,3]= str(weather)\n",
    "#     df.iloc[0:1,4] = int(temp)\n",
    "#     df.iloc[0:1,5]= int(temp_feel)\n",
    "#     df.iloc[0:1,6] = int(humidity)\n",
    "#     df.iloc[0:1,7]= int(windspeed)\n",
    "#     df.iloc[0:1,8]=  pd.to_datetime(str(date)).dayofyear   \n",
    "#     time = str(time) \n",
    "#     df.iloc[0:1,9] = int(time[0:2])\n",
    "    \n",
    "#     make_season_holiday_dc(df)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "# # Pipeline pour la prediction automatique pour Washington DC : \n",
    "# def run_df_dc():\n",
    "        \n",
    "#     df_app = make_df_init(index=40)\n",
    "#     stat_api_3h(df_app, lat='38.8951', lon='77.0364')  \n",
    "#     make_season_holiday_dc(df_app)\n",
    "#     converstion_fr_dc(df_app)\n",
    "#     return df_app\n",
    "\n",
    "\n",
    "# # Pipeline pour la prediction automatique pour Lille : \n",
    "\n",
    "# def run_df_lille():\n",
    "    \n",
    "#     # Prendre la 1ere lignes du datafram pour le jour d'aujourd'hui\n",
    "#     df_app = make_df_init(index=40)\n",
    "#     stat_api_3h(df_app, lat='50.62925', lon='3.057256')\n",
    "#     make_season_holiday_fr(df_app)\n",
    "#     return df_app\n",
    "\n",
    "\n",
    "# def run_df_meteo_1h_lille():\n",
    "    \n",
    "#     # Prendre la 1ere lignes du datafram pour le jour d'aujourd'hui\n",
    "#     df_app = make_df_init(48)\n",
    "#     stat_api_1h(df_app, lat='50.62925', lon='3.057256')\n",
    "#     add_day_hour_from_nom(df_app)\n",
    "#     make_season_holiday_fr(df_app)\n",
    "#     return df_app\n",
    "\n",
    "\n",
    "# def run_df_meteo_1h_dc():\n",
    "    \n",
    "#     # Prendre la 1ere lignes du datafram pour le jour d'aujourd'hui\n",
    "#     df_app = make_df_init(48)\n",
    "#     stat_api_1h(df_app, lat='38.8951', lon='77.0364')   \n",
    "#     add_day_hour_from_nom(df_app)\n",
    "#     make_season_holiday_fr(df_app)\n",
    "#     converstion_fr_dc(df_app)\n",
    "#     return df_app\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pipelines fonctions avec pandas \n",
    "\n",
    "\n",
    "# # J'importe et je modifie le df de train pour en faire le df de prédiction de base avec les colonnes dans le bonnes ordres. \n",
    "# def make_df_init(index):\n",
    "#     df = pd.read_csv('./data/train.csv')\n",
    "#     df.drop('Unnamed: 0', axis=1, inplace = True)\n",
    "#     df.drop('datetime', axis=1, inplace=True)\n",
    "#     df.drop(columns=['registered', 'casual'], index=1, inplace=True)\n",
    "#     df = pd.DataFrame(columns=df.drop('count', axis=1).keys(), index=np.arange(0,index,1))\n",
    "   \n",
    "#     return df \n",
    "\n",
    "# def stat_api_3h(df, lat, lon):\n",
    "#     date = []\n",
    "#     temp = []\n",
    "#     atemp = []\n",
    "#     humidity = []\n",
    "#     windspeed = []\n",
    "#     weather = []\n",
    "#     with closing(urlopen(f'http://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid=6bda77c15824913b0353424425dfeb64')) as f:\n",
    "#         cityEph = json.loads(f.read())\n",
    "#         for i in range(0, len(cityEph['list'])):\n",
    "#             temp.append(cityEph['list'][i]['main']['temp'])\n",
    "#             atemp.append(cityEph['list'][i]['main']['feels_like'])\n",
    "#             humidity.append(cityEph['list'][i]['main']['humidity'])\n",
    "#             windspeed.append(cityEph['list'][i]['wind']['speed'])\n",
    "#             weather.append(cityEph['list'][i]['weather'][0]['main'])\n",
    "#             date.append(cityEph['list'][i]['dt_txt'])\n",
    "            \n",
    "#     df['day'] = [ i for i in date]\n",
    "#     df['hour']  = pd.to_datetime(df['day']).dt.hour\n",
    "#     df['day']  = pd.to_datetime(df['day']).dt.dayofyear\n",
    "#     df['temp'] = [ i for i in temp]\n",
    "#     df['atemp'] = [ i for i in atemp]\n",
    "#     df['humidity'] = [ i for i in humidity]\n",
    "#     df['windspeed'] = [ i for i in windspeed]\n",
    "#     df['weather'] = [ str(i) for i in weather]\n",
    "#     df['temp'] = df['temp'] - 273.15\n",
    "#     df['atemp'] = df['atemp'] - 273.15\n",
    "    \n",
    "    \n",
    "# def stat_api_1h(df, lat, lon):\n",
    "#     date = []\n",
    "#     temp = []\n",
    "#     atemp = []\n",
    "#     humidity = []\n",
    "#     windspeed = []\n",
    "#     weather = []\n",
    "#     with closing(urlopen(f'https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&exclude=minutely&appid=6bda77c15824913b0353424425dfeb64')) as f:\n",
    "#         cityEph = json.loads(f.read())    \n",
    "#         for i in range(0, len(cityEph['hourly'])): \n",
    "\n",
    "#             temp.append(cityEph['hourly'][i]['temp'])\n",
    "#             atemp.append(cityEph['hourly'][i]['feels_like'])\n",
    "#             humidity.append(cityEph['hourly'][i]['humidity'])\n",
    "#             windspeed.append(cityEph['hourly'][i]['wind_speed'])\n",
    "#             weather.append(cityEph['hourly'][i]['weather'][0]['main'])\n",
    "#             date.append(cityEph['hourly'][i]['dt'])\n",
    "            \n",
    "#                                 # hourly : 48h de data par heure  ; \n",
    "#                                 # current : actuel \n",
    "#                                 # daily : 8j \n",
    "    \n",
    "    \n",
    "#     df['temp'] = [ i for i in temp]\n",
    "#     df['atemp'] = [ i for i in atemp]\n",
    "#     df['humidity'] = [ i for i in humidity]\n",
    "#     df['windspeed'] = [ i for i in windspeed]\n",
    "#     df['weather'] = [ str(i) for i in weather]\n",
    "#     df['temp'] = df['temp'] - 273.15\n",
    "#     df['atemp'] = df['atemp'] - 273.15\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# def make_season_holiday_dc(df):\n",
    "\n",
    "#     # Season \n",
    "#     df['season'][(df['day'] >= 78 ) & (df['day'] < 141 )] = 1\n",
    "#     df['season'][(df['day'] >= 141) & (df['day'] < 365 ) ] = 2\n",
    "#     df['season'][(df['day'] >= 365) & (df['day'] < 356 ) ] = 3\n",
    "#     df['season'][(df['day'] >= 356) | (df['day'] < 78 ) ] = 4\n",
    "\n",
    "#     # Holliday For Washington \n",
    "#     df['holiday'] = 0 \n",
    "#     df['holiday'][(df['day'] >= 357) | (df['day'] <= 2 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 52) & (df['day'] <= 56 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 69) & (df['day'] <= 70 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 101) & (df['day'] <= 108 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 185) & (df['day'] <= 240 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 279) & (df['day'] <= 283 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 315) & (df['day'] <= 329 ) ] = 1\n",
    "\n",
    "#     # Férié for Washington \n",
    "#     df['holiday'][df['day'] == 17 ] = 1\n",
    "#     df['holiday'][df['day'] == 26 ] = 1\n",
    "#     df['holiday'][df['day'] == 150 ] = 1\n",
    "#     df['holiday'][df['day'] == 129 ] = 1\n",
    "#     df['holiday'][df['day'] == 305 ] = 1\n",
    "#     df['holiday'][df['day'] == 308 ] = 1\n",
    "        \n",
    "#     df['workingday'] = 0\n",
    "#     for i in np.arange(1,365,7):\n",
    "#         df['workingday'][(df['day'] == i) | (df['day'] == i + 1) ] = 1\n",
    "        \n",
    "            \n",
    "#     df.rename(columns = {'weather' : 'weather2'}, inplace = True)\n",
    "#     df.insert(4, 'weather', 0)\n",
    "    \n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_1_from_api, weather_choice_1_from_page.lower()])] = 1\n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_2_from_api, weather_choice_2_from_page.lower()])] = 2\n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_3_from_api, weather_choice_3_from_page.lower()])] = 3\n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_4_from_api, weather_choice_4_from_page.lower()])] = 4\n",
    "#     df.drop('weather2', axis=1, inplace=True)\n",
    "    \n",
    "#     df['weather'] = df['weather'].astype(int)\n",
    "#     df['season'] = df['season'].astype(int)\n",
    "\n",
    "    \n",
    "    \n",
    "# def make_season_holiday_fr(df):\n",
    "\n",
    "#     # just need columns day to run this functions and \n",
    "\n",
    "#     # Season \n",
    "#     df['season'][(df['day'] >= 78 ) & (df['day'] < 141 )] = 1\n",
    "#     df['season'][(df['day'] >= 141) & (df['day'] < 365 ) ] = 2\n",
    "#     df['season'][(df['day'] >= 365) & (df['day'] < 356 ) ] = 3\n",
    "#     df['season'][(df['day'] >= 356) | (df['day'] < 78 ) ] = 4\n",
    "\n",
    "\n",
    "#     # Holliday France - Lille\n",
    "#     df['holiday'] = 0 \n",
    "#     df['holiday'][(df['day'] >= 352) | (df['day'] < 3 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 36) & (df['day'] < 52 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 99) & (df['day'] < 115 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 145) & (df['day'] < 150 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 188) & (df['day'] < 244 ) ] = 1\n",
    "#     df['holiday'][(df['day'] >= 296) & (df['day'] < 312 ) ] = 1\n",
    "\n",
    "#     # Férié \n",
    "#     df['holiday'][df['day'] == 17 ] = 1\n",
    "#     df['holiday'][df['day'] == 26 ] = 1\n",
    "#     df['holiday'][df['day'] == 150 ] = 1\n",
    "#     df['holiday'][df['day'] == 129 ] = 1\n",
    "#     df['holiday'][df['day'] == 305 ] = 1\n",
    "#     df['holiday'][df['day'] == 308 ] = 1\n",
    "\n",
    "#     df['workingday'] = 0\n",
    "#     for i in np.arange(1,365,7):\n",
    "#         df['workingday'][(df['day'] == i) | (df['day'] == i + 1) ] = 1\n",
    "        \n",
    "        \n",
    "#     df.rename(columns = {'weather' : 'weather2'}, inplace = True)\n",
    "#     df.insert(4, 'weather', 0)\n",
    "        \n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_1_from_api, weather_choice_1_from_page.lower()])] = 1\n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_2_from_api, weather_choice_2_from_page.lower()])] = 2\n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_3_from_api, weather_choice_3_from_page.lower()])] = 3\n",
    "#     df['weather'][df['weather2'].str.lower().isin([weather_choice_4_from_api, weather_choice_4_from_page.lower()])] = 4\n",
    "#     df.drop('weather2', axis=1, inplace=True)\n",
    "    \n",
    "#     df['weather'] = df['weather'].astype(int)\n",
    "#     df['season'] = df['season'].astype(int)\n",
    "    \n",
    "    \n",
    "# def add_day_hour_from_nom(df):\n",
    "\n",
    "#     day = datetime.now()\n",
    "#     df['day'] = day                          \n",
    "#     df['hour']  = pd.to_datetime(df['day']).dt.hour\n",
    "#     df['day']  = pd.to_datetime(df['day']).dt.dayofyear\n",
    "    \n",
    "#     for i in range(0, len(df['hour'])):\n",
    "        \n",
    "#         df.iloc[i,9] += i \n",
    "#         if df.iloc[i,9] >= 24 :\n",
    "#             df.iloc[i,9] -= 24\n",
    "#             df.iloc[i,8] += 1\n",
    "#         else:\n",
    "#             df.iloc[i,9] += 1 \n",
    "    \n",
    "#     return df\n",
    "\n",
    "    \n",
    "    \n",
    "#     # Decalage horaire : -5h \n",
    "# def converstion_fr_dc(df):\n",
    "    \n",
    "#         for i in range(0, len(df['hour'])):\n",
    "        \n",
    "#             if df.iloc[i,9] <= 4 :\n",
    "#                 df.iloc[i,9] += 19\n",
    "#             else:\n",
    "#                 df.iloc[i,9] -= 5\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "# # faire graph count vélo par jour des 20 jours précédents la requêtes + 10 des jours suivants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename = 'model_all.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the model with pickle file \n",
    "# save_model(best,'lightgbm-location-velo')\n",
    "# Tuned_rf = tune_model(rf) \n",
    "# Tuned_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime('2011-10-30').dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add new ROW\n",
    "# df=df.append({'Name' : 'Apple' , 'Price' : 23, 'Stock' : 'No'} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_weather(x):\n",
    "    if x == 1:\n",
    "        x = 4\n",
    "    elif x == 2:\n",
    "        x = 3\n",
    "    elif x == 3:\n",
    "        x = 2 \n",
    "    elif x == 4:\n",
    "        x = 1\n",
    "        \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_season(x):\n",
    "    if x == 1:\n",
    "        x = 3\n",
    "    elif x == 2:\n",
    "        x = 4\n",
    "    elif x == 3:\n",
    "        x = 2 \n",
    "    elif x == 4:\n",
    "        x = 1\n",
    "        \n",
    "    return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7163/1450698090.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-08-17 08:00:00', 'season' : 0, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : 75, 'atemp' : 72, 'humidity' : 2, 'windspeed' : 500, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2012-07-15 09:00:00', 'season' : 0, 'holiday' : 0, 'workingday' : 0, 'weather' : 1, 'temp' : 96, 'atemp' : 88, 'humidity' : 2, 'windspeed' : 500.0, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-08-10 11:00:00', 'season' : 1, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : 200, 'atemp' : 155, 'humidity' : 51, 'windspeed' : 0, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-08-12 19:00:00', 'season' : 2, 'holiday' : 0, 'workingday' : 0, 'weather' : 3, 'temp' : 111, 'atemp' : 110, 'humidity' : 4, 'windspeed' : 225, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-12-08 18:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 9, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-12-24 17:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -110, 'atemp' : -108, 'humidity' : 25, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-11-25 16:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 69, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-12-27 15:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 1, 'temp' : -500, 'atemp' : -55, 'humidity' : 0, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-07-21 15:00:00', 'season' : 0, 'holiday' : 0, 'workingday' : 0, 'weather' : 2, 'temp' : 75, 'atemp' : 72.5, 'humidity' : 41, 'windspeed' : 500, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-06-04 13:00:00', 'season' : 1, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : 200, 'atemp' : 155, 'humidity' : 55, 'windspeed' : 0, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-06-05 14:00:00', 'season' : 2, 'holiday' : 0, 'workingday' : 0, 'weather' : 3, 'temp' : 111, 'atemp' : 110, 'humidity' : 25, 'windspeed' : 225, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-11-28 15:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 39, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-12-27 09:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 3, 'temp' : -110, 'atemp' : -108, 'humidity' : 10, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2011-11-27 12:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 57, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
      "/tmp/ipykernel_7163/1450698090.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data_all = train_data_all.append({'datetime' : '2012-01-02 16:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -500, 'atemp' : -55, 'humidity' : 84, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "train_data_all =  pd.read_csv('../data/train.csv')\n",
    "train_data_all.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-08-17 08:00:00', 'season' : 0, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : 75, 'atemp' : 72, 'humidity' : 2, 'windspeed' : 500, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2012-07-15 09:00:00', 'season' : 0, 'holiday' : 0, 'workingday' : 0, 'weather' : 1, 'temp' : 96, 'atemp' : 88, 'humidity' : 2, 'windspeed' : 500.0, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-08-10 11:00:00', 'season' : 1, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : 200, 'atemp' : 155, 'humidity' : 51, 'windspeed' : 0, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-08-12 19:00:00', 'season' : 2, 'holiday' : 0, 'workingday' : 0, 'weather' : 3, 'temp' : 111, 'atemp' : 110, 'humidity' : 4, 'windspeed' : 225, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-12-08 18:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 9, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-12-24 17:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -110, 'atemp' : -108, 'humidity' : 25, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-11-25 16:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 69, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-12-27 15:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 1, 'temp' : -500, 'atemp' : -55, 'humidity' : 0, 'windspeed' : 110, 'casual' : 0, 'registered' : 0,  'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-07-21 15:00:00', 'season' : 0, 'holiday' : 0, 'workingday' : 0, 'weather' : 2, 'temp' : 75, 'atemp' : 72.5, 'humidity' : 41, 'windspeed' : 500, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-06-04 13:00:00', 'season' : 1, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : 200, 'atemp' : 155, 'humidity' : 55, 'windspeed' : 0, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-06-05 14:00:00', 'season' : 2, 'holiday' : 0, 'workingday' : 0, 'weather' : 3, 'temp' : 111, 'atemp' : 110, 'humidity' : 25, 'windspeed' : 225, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-11-28 15:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 39, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-12-27 09:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 3, 'temp' : -110, 'atemp' : -108, 'humidity' : 10, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2011-11-27 12:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -48, 'atemp' : -55, 'humidity' : 57, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "train_data_all = train_data_all.append({'datetime' : '2012-01-02 16:00:00', 'season' : 4, 'holiday' : 0, 'workingday' : 0, 'weather' : 4, 'temp' : -500, 'atemp' : -55, 'humidity' : 84, 'windspeed' : 110, 'casual' : 0, 'registered' : 0, 'count' : 0}, ignore_index = True)\n",
    "\n",
    "train_data_all['day'] = pd.to_datetime(train_data_all['datetime']).dt.dayofyear\n",
    "train_data_all['hour'] = pd.to_datetime(train_data_all['datetime']).dt.hour\n",
    "train_data_all['year'] = pd.to_datetime(train_data_all['datetime']).dt.year\n",
    "\n",
    "train_data_all.drop(['datetime'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "for i in range(0, len(train_data_all.iloc[:,0])) :\n",
    "    train_data_all.iloc[i,0] = transform_season(int(train_data_all.iloc[i,0] ))\n",
    "    \n",
    "for i in range(0, len(train_data_all.iloc[:,3])) :\n",
    "    train_data_all.iloc[i,3] = transform_weather(int(train_data_all.iloc[i,3] ))\n",
    "\n",
    "\n",
    "train_data_all = train_data_all.drop(['registered','casual'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "augmentation = np.linspace(0, (144 * 100 / 230) *  train_data_all.shape[0] , train_data_all.shape[0])\n",
    "\n",
    "# train_data_all['augmentation'] = 0 \n",
    "# train_data_all['augmentation'] = augmentation # Etape suivante : Il faut order par day avant de drop datetime pour que ce soit cohérent \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data_all_X = train_data_all.drop('count', axis = 1)\n",
    "train_data_all_y = train_data_all['count']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data_all =  pd.read_csv('../data/test.csv')\n",
    "test_data_all.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_data_all['day'] = pd.to_datetime(test_data_all['datetime']).dt.dayofyear\n",
    "test_data_all['hour'] = pd.to_datetime(test_data_all['datetime']).dt.hour\n",
    "test_data_all['year'] = pd.to_datetime(test_data_all['datetime']).dt.year\n",
    "test_data_all.drop(['datetime'], axis=1, inplace=True)\n",
    "\n",
    "for i in range(0, len(test_data_all.iloc[:,0])) :\n",
    "    test_data_all.iloc[i,0] = transform_season(int(test_data_all.iloc[i,0] ))\n",
    "    \n",
    "for i in range(0, len(test_data_all.iloc[:,3])) :\n",
    "    test_data_all.iloc[i,3] = transform_weather(int(test_data_all.iloc[i,3] ))\n",
    "\n",
    "# augmentation = np.linspace(0, (144 * 100 / 230) *  test_data_all.shape[0] / 100 , test_data_all.shape[0])\n",
    "# test_data_all['augmentation'] = augmentation\n",
    "\n",
    "\n",
    "test_data_all = test_data_all.drop(['registered','casual'], axis=1)\n",
    "\n",
    "test_data_all_X = test_data_all.drop('count', axis = 1)\n",
    "test_data_all_y = test_data_all['count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"season\":3.0,\"holiday\":0.0,\"workingday\":0.0,\"weather\":4.0,\"temp\":9.84,\"atemp\":14.395,\"humidity\":81.0,\"windspeed\":0.0,\"count\":16.0,\"day\":1.0,\"hour\":0.0,\"year\":2011.0}'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "data = train_data_all.iloc[0,:].to_json()\n",
    "data = json.dumps(data)\n",
    "eval(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.parse\n",
    "# import urllib.request\n",
    "\n",
    "\n",
    "\n",
    "# test_post = urllib.parse.urlencode({\"season\": 3.0 ,\"holiday\":0.0,\"workingday\":0.0,\"weather\":4.0,\"temp\":9.84,\"atemp\":14.395,\"humidity\":81.0,\"windspeed\":0.0,\"count\":16.0,\"day\":1.0,\"hour\":0.0,\"year\":2011.0})\n",
    "\n",
    "\n",
    "\n",
    "# url = 'http://127.0.0.1:8000/predict/xgboost/'\n",
    "\n",
    "\n",
    "# with urllib.request.urlopen(url, eval(test_post)) as f:\n",
    "#     print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------------- Casual and registered   \n",
    "# # ---------------------------------------------------------------- Train set => \n",
    "# data_train =  pd.read_csv('../data/train.csv')\n",
    "# data_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# data_train['day'] = pd.to_datetime(data_train['datetime']).dt.dayofyear\n",
    "# data_train['hour'] = pd.to_datetime(data_train['datetime']).dt.hour\n",
    "# data_train['year'] = pd.to_datetime(data_train['datetime']).dt.year\n",
    "# data_train.drop(['datetime','count'], axis=1, inplace=True)\n",
    "\n",
    "# for i in range(0, len(data_train.iloc[:,0])) :\n",
    "#     data_train.iloc[i,0] = transform_season(int(data_train.iloc[i,0] ))\n",
    "\n",
    "\n",
    "# casual_train = data_train.drop('registered', axis=1)\n",
    "# registered_train = data_train.drop('casual', axis=1)\n",
    "\n",
    "# casual_train_X = casual_train.drop('casual', axis = 1)\n",
    "# casual_train_y = casual_train['casual']\n",
    "# registered_train_X = registered_train.drop('registered', axis=1)\n",
    "# registered_train_y = registered_train['registered']\n",
    "\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------------- Test set => \n",
    "\n",
    "# data_test =  pd.read_csv('../data/test.csv')\n",
    "# data_test.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# data_test['day'] = pd.to_datetime(data_test['datetime']).dt.dayofyear\n",
    "# data_test['hour'] = pd.to_datetime(data_test['datetime']).dt.hour\n",
    "# data_test['year'] = pd.to_datetime(data_test['datetime']).dt.year\n",
    "# data_test.drop(['datetime','count'], axis=1, inplace=True)\n",
    "\n",
    "# for i in range(0, len(data_test.iloc[:,0])) :\n",
    "#     data_test.iloc[i,0] = transform_season(int(data_test.iloc[i,0] ))\n",
    "\n",
    "\n",
    "# casual_test = data_test.drop('registered', axis=1)\n",
    "# registered_test = data_test.drop('casual', axis=1)\n",
    "\n",
    "# casual_test_X = casual_test.drop('casual', axis = 1)\n",
    "# casual_test_y = casual_test['casual']\n",
    "# registered_test_X = registered_test.drop('registered', axis=1)\n",
    "# registered_test_y = registered_test['registered']\n",
    "# casual_test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire catégories : Temps dangereux : 0 ou 1\n",
    "# Ajouter des lignes > 60° comme étant dangereux idem < à -50 \n",
    "# Ajouter les lignes associés aux conditions métérologiques extremes encodé par la colonne temps dangereux avec 0 count. \n",
    "\n",
    "# Faire un booléens : journée idéale : Entre 23 et 35 + windspeed entre 3 et 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBRegressor' object has no attribute 'XGBRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000016?line=9'>10</a>\u001b[0m encode_pipeline \u001b[39m=\u001b[39m make_pipeline(StandardScaler(with_mean\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, with_std\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), OneHotEncoder(handle_unknown \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000016?line=11'>12</a>\u001b[0m preprocessor \u001b[39m=\u001b[39m make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000016?line=13'>14</a>\u001b[0m xgboost \u001b[39m=\u001b[39m xgboost\u001b[39m.\u001b[39;49mXGBRegressor(booster\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgbtree\u001b[39m\u001b[39m'\u001b[39m, colsample_bytree \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m, eta \u001b[39m=\u001b[39m \u001b[39m0.3\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,max_depth \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m, max_leaves\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, n_estimators \u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreg:linear\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, reg_alpha\u001b[39m=\u001b[39m\u001b[39m1.6666666666666667\u001b[39m, reg_lambda \u001b[39m=\u001b[39m\u001b[39m1.9791666666666667\u001b[39m, subsample_freq\u001b[39m=\u001b[39m\u001b[39m0.75\u001b[39m, tree_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000016?line=14'>15</a>\u001b[0m model_xgboost \u001b[39m=\u001b[39m make_pipeline(preprocessor,  xgboost)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000016?line=15'>16</a>\u001b[0m model_xgboost\u001b[39m.\u001b[39mfit(train_data_all_X , train_data_all_y)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBRegressor' object has no attribute 'XGBRegressor'"
     ]
    }
   ],
   "source": [
    "# Meilleur model : \n",
    "# Preprocessing et model xgboost :0.8922942586728222 (8s)\n",
    "\n",
    "logfunc = FunctionTransformer(func=np.log1p, inverse_func=np.exp, check_inverse=False)\n",
    "\n",
    "numerical_features = ['temp','atemp','humidity','windspeed','day','hour']\n",
    "encode_column = ['season','workingday','weather','holiday','hour','year']\n",
    "\n",
    "numerical_pipeline = make_pipeline( logfunc, SimpleImputer(), MaxAbsScaler())\n",
    "encode_pipeline = make_pipeline(StandardScaler(with_mean=False, with_std=True), OneHotEncoder(handle_unknown = 'ignore'))\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n",
    "\n",
    "xgboost = xgboost.XGBRegressor(booster='gbtree', colsample_bytree = 0.5, eta = 0.3, gamma=0,max_depth = 6, max_leaves=0, n_estimators =100, objective='reg:linear', random_state=32, reg_alpha=1.6666666666666667, reg_lambda =1.9791666666666667, subsample_freq=0.75, tree_method='auto')\n",
    "model_xgboost = make_pipeline(preprocessor,  xgboost)\n",
    "model_xgboost.fit(train_data_all_X , train_data_all_y)\n",
    "model_xgboost.score(test_data_all_X, test_data_all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename = 'xgboost.pkl'\n",
    "# pickle.dump(model_xgboost, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(train_data_all_X.iloc[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.000e+00,  0.000e+00,  0.000e+00,  1.000e+00, -5.000e+02,\n",
       "       -5.500e+01,  8.400e+01,  1.100e+02,  2.000e+00,  1.600e+01,\n",
       "        2.012e+03])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayoub/anaconda3/envs/envIA/lib/python3.10/site-packages/pandas/core/internals/blocks.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([25.989832  , 47.185387  , 34.936436  , ..., -6.3404784 ,\n",
       "       12.650763  ,  0.89120704], dtype=float32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost.predict(train_data_all_X.iloc[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"season\":{\"0\":3,\"1\":3,\"2\":3,\"3\":3,\"4\":3,\"5\":3,\"6\":3,\"7\":3,\"8\":3,\"9\":3,\"10\":3,\"11\":3,\"12\":3,\"13\":3,\"14\":3,\"15\":3,\"16\":3,\"17\":3,\"18\":3,\"19\":3,\"20\":3,\"21\":3,\"22\":3,\"23\":3,\"24\":3,\"25\":3,\"26\":3,\"27\":3,\"28\":3,\"29\":3,\"30\":3,\"31\":3,\"32\":3,\"33\":3,\"34\":3,\"35\":3,\"36\":3,\"37\":3,\"38\":3,\"39\":3},\"holiday\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0,\"5\":0,\"6\":0,\"7\":0,\"8\":0,\"9\":0,\"10\":0,\"11\":0,\"12\":0,\"13\":0,\"14\":0,\"15\":0,\"16\":0,\"17\":0,\"18\":0,\"19\":0,\"20\":0,\"21\":0,\"22\":0,\"23\":0,\"24\":0,\"25\":0,\"26\":0,\"27\":0,\"28\":0,\"29\":0,\"30\":0,\"31\":0,\"32\":0,\"33\":0,\"34\":0,\"35\":0,\"36\":0,\"37\":0,\"38\":0,\"39\":0},\"workingday\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0,\"5\":0,\"6\":0,\"7\":0,\"8\":0,\"9\":0,\"10\":0,\"11\":0,\"12\":0,\"13\":0,\"14\":0,\"15\":0,\"16\":0,\"17\":0,\"18\":0,\"19\":0,\"20\":0,\"21\":0,\"22\":0,\"23\":0,\"24\":0,\"25\":0,\"26\":0,\"27\":0,\"28\":0,\"29\":0,\"30\":0,\"31\":0,\"32\":0,\"33\":0,\"34\":0,\"35\":0,\"36\":0,\"37\":0,\"38\":0,\"39\":0},\"weather\":{\"0\":4,\"1\":4,\"2\":4,\"3\":4,\"4\":4,\"5\":3,\"6\":4,\"7\":4,\"8\":4,\"9\":4,\"10\":4,\"11\":4,\"12\":4,\"13\":3,\"14\":3,\"15\":3,\"16\":3,\"17\":3,\"18\":2,\"19\":2,\"20\":3,\"21\":3,\"22\":3,\"23\":3,\"24\":3,\"25\":3,\"26\":3,\"27\":3,\"28\":3,\"29\":2,\"30\":3,\"31\":2,\"32\":3,\"33\":3,\"34\":3,\"35\":3,\"36\":3,\"37\":2,\"38\":2,\"39\":2},\"temp\":{\"0\":9.84,\"1\":9.02,\"2\":9.02,\"3\":9.84,\"4\":9.84,\"5\":9.84,\"6\":9.02,\"7\":8.2,\"8\":9.84,\"9\":13.12,\"10\":15.58,\"11\":14.76,\"12\":17.22,\"13\":18.86,\"14\":18.86,\"15\":18.04,\"16\":17.22,\"17\":18.04,\"18\":17.22,\"19\":17.22,\"20\":16.4,\"21\":16.4,\"22\":16.4,\"23\":18.86,\"24\":18.86,\"25\":18.04,\"26\":17.22,\"27\":18.86,\"28\":18.86,\"29\":17.22,\"30\":16.4,\"31\":16.4,\"32\":15.58,\"33\":14.76,\"34\":14.76,\"35\":14.76,\"36\":14.76,\"37\":14.76,\"38\":13.94,\"39\":13.94},\"atemp\":{\"0\":14.395,\"1\":13.635,\"2\":13.635,\"3\":14.395,\"4\":14.395,\"5\":12.88,\"6\":13.635,\"7\":12.88,\"8\":14.395,\"9\":17.425,\"10\":19.695,\"11\":16.665,\"12\":21.21,\"13\":22.725,\"14\":22.725,\"15\":21.97,\"16\":21.21,\"17\":21.97,\"18\":21.21,\"19\":21.21,\"20\":20.455,\"21\":20.455,\"22\":20.455,\"23\":22.725,\"24\":22.725,\"25\":21.97,\"26\":21.21,\"27\":22.725,\"28\":22.725,\"29\":21.21,\"30\":20.455,\"31\":20.455,\"32\":19.695,\"33\":17.425,\"34\":16.665,\"35\":16.665,\"36\":17.425,\"37\":17.425,\"38\":16.665,\"39\":16.665},\"humidity\":{\"0\":81,\"1\":80,\"2\":80,\"3\":75,\"4\":75,\"5\":75,\"6\":80,\"7\":86,\"8\":75,\"9\":76,\"10\":76,\"11\":81,\"12\":77,\"13\":72,\"14\":72,\"15\":77,\"16\":82,\"17\":82,\"18\":88,\"19\":88,\"20\":87,\"21\":87,\"22\":94,\"23\":88,\"24\":88,\"25\":94,\"26\":100,\"27\":94,\"28\":94,\"29\":77,\"30\":76,\"31\":71,\"32\":76,\"33\":81,\"34\":71,\"35\":66,\"36\":66,\"37\":76,\"38\":81,\"39\":71},\"windspeed\":{\"0\":0.0,\"1\":0.0,\"2\":0.0,\"3\":0.0,\"4\":0.0,\"5\":6.0032,\"6\":0.0,\"7\":0.0,\"8\":0.0,\"9\":0.0,\"10\":16.9979,\"11\":19.0012,\"12\":19.0012,\"13\":19.9995,\"14\":19.0012,\"15\":19.9995,\"16\":19.9995,\"17\":19.0012,\"18\":16.9979,\"19\":16.9979,\"20\":16.9979,\"21\":12.998,\"22\":15.0013,\"23\":19.9995,\"24\":19.9995,\"25\":16.9979,\"26\":19.0012,\"27\":12.998,\"28\":12.998,\"29\":19.9995,\"30\":12.998,\"31\":15.0013,\"32\":15.0013,\"33\":15.0013,\"34\":16.9979,\"35\":19.9995,\"36\":8.9981,\"37\":12.998,\"38\":11.0014,\"39\":11.0014},\"day\":{\"0\":1,\"1\":1,\"2\":1,\"3\":1,\"4\":1,\"5\":1,\"6\":1,\"7\":1,\"8\":1,\"9\":1,\"10\":1,\"11\":1,\"12\":1,\"13\":1,\"14\":1,\"15\":1,\"16\":1,\"17\":1,\"18\":1,\"19\":1,\"20\":1,\"21\":1,\"22\":1,\"23\":1,\"24\":2,\"25\":2,\"26\":2,\"27\":2,\"28\":2,\"29\":2,\"30\":2,\"31\":2,\"32\":2,\"33\":2,\"34\":2,\"35\":2,\"36\":2,\"37\":2,\"38\":2,\"39\":2},\"hour\":{\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,\"6\":6,\"7\":7,\"8\":8,\"9\":9,\"10\":10,\"11\":11,\"12\":12,\"13\":13,\"14\":14,\"15\":15,\"16\":16,\"17\":17,\"18\":18,\"19\":19,\"20\":20,\"21\":21,\"22\":22,\"23\":23,\"24\":0,\"25\":1,\"26\":2,\"27\":3,\"28\":4,\"29\":6,\"30\":7,\"31\":8,\"32\":9,\"33\":10,\"34\":11,\"35\":12,\"36\":13,\"37\":14,\"38\":15,\"39\":16},\"year\":{\"0\":2011,\"1\":2011,\"2\":2011,\"3\":2011,\"4\":2011,\"5\":2011,\"6\":2011,\"7\":2011,\"8\":2011,\"9\":2011,\"10\":2011,\"11\":2011,\"12\":2011,\"13\":2011,\"14\":2011,\"15\":2011,\"16\":2011,\"17\":2011,\"18\":2011,\"19\":2011,\"20\":2011,\"21\":2011,\"22\":2011,\"23\":2011,\"24\":2011,\"25\":2011,\"26\":2011,\"27\":2011,\"28\":2011,\"29\":2011,\"30\":2011,\"31\":2011,\"32\":2011,\"33\":2011,\"34\":2011,\"35\":2011,\"36\":2011,\"37\":2011,\"38\":2011,\"39\":2011}}'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_all_X.iloc[:40,:].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather  temp  atemp  humidity  windspeed  \\\n",
       "0       1        0           0        1    10     15        15         15   \n",
       "\n",
       "   day  hour  \n",
       "0   88    16  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season = train_data_all.iloc[-1,0]\n",
    "holiday = train_data_all.iloc[-1,1]\n",
    "workingday = train_data_all.iloc[-1,2]\n",
    "weather = train_data_all.iloc[-1,3]\n",
    "temp = train_data_all.iloc[-1,4]\n",
    "atemp = train_data_all.iloc[-1,5]\n",
    "humidity = train_data_all.iloc[-1,6]\n",
    "windspeed = train_data_all.iloc[-1,7]\n",
    "day = train_data_all.iloc[-1,8]\n",
    "hour = train_data_all.iloc[-1,9]\n",
    "year = train_data_all.iloc[-1,10]\n",
    "\n",
    "pred = {'season' : season, 'holiday' : holiday, 'workingday' : workingday, 'weather' : 1, 'temp' : 10, 'atemp' : 15, 'humidity' : 15, 'windspeed' :15, 'day' :88, 'hour' : 16 }\n",
    "df = pd.DataFrame(pred, index=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "savedmodel = open('./lgbm.pkl', 'rb')\n",
    "model = pickle.load(savedmodel)\n",
    "savedmodel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([258.62763983])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = np.array((0,1,2,0,1,2,1,2,1,10,2011))\n",
    "pred2 = pred2.reshape(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_all_X.iloc[-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayoub/anaconda3/envs/envIA/lib/python3.10/site-packages/pandas/core/internals/blocks.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9190960274167893"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing et model lgbm : 0.9190960274167893 (8s)\n",
    "\n",
    "logfunc = FunctionTransformer(func=np.log1p, inverse_func=np.exp, check_inverse=False)\n",
    "\n",
    "numerical_features = ['temp','atemp','humidity','windspeed','day','hour']\n",
    "encode_column = ['season','workingday','weather','holiday','hour','year']\n",
    "\n",
    "numerical_pipeline = make_pipeline( logfunc, SimpleImputer(), MaxAbsScaler())\n",
    "encode_pipeline = make_pipeline(StandardScaler(with_mean=False, with_std=True), OneHotEncoder())\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n",
    "\n",
    "model_lgbm =  lightgbm.LGBMRegressor(random_state=2, colsample_bytree=0.7395, learning_rate=0.12, max_bin=1023, max_depth=8, reg_lambda=1,reg_alpha=0, subsample_freq=7)\n",
    "model_lgbm = make_pipeline(preprocessor, model_lgbm)\n",
    "model_lgbm.fit(train_data_all_X , train_data_all_y)\n",
    "model_lgbm.score(test_data_all_X, test_data_all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Meilleur model n2 lgbm : \n",
    "# # Preprocessing et model lgbm :0.9118832634446215 (8s)\n",
    "\n",
    "# logfunc = FunctionTransformer(func=np.log1p, inverse_func=np.exp, check_inverse=False)\n",
    "\n",
    "# numerical_features = ['temp','atemp','humidity','windspeed','day','hour']\n",
    "# encode_column = ['season','workingday','weather','holiday','hour','year']\n",
    "\n",
    "# numerical_pipeline = make_pipeline( logfunc, SimpleImputer(), MaxAbsScaler())\n",
    "# encode_pipeline = make_pipeline(StandardScaler(with_mean=False, with_std=True), OneHotEncoder())\n",
    "\n",
    "# preprocessor = make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n",
    "\n",
    "# model_lgbm = make_pipeline(preprocessor,  lightgbm.LGBMRegressor(random_state=2, min_data_in_leaf=100, max_bin=1023, reg_alpha=0, subsample_freq=56))\n",
    "# model_lgbm.fit(train_data_all_X , train_data_all_y)\n",
    "# model_lgbm.score(test_data_all_X, test_data_all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lgbm.predict(test_data_all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3757.4719475925376"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_data_all_y, y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.486814391122323"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(test_data_all_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.09404334027951"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test_data_all_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayoub/anaconda3/envs/envIA/lib/python3.10/site-packages/pandas/core/internals/blocks.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8884707061384725"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing et model ExtraTreesRegressor : 0.9151391659342789 (4.6seconde)\n",
    "\n",
    "logfunc = FunctionTransformer(func=np.log1p, inverse_func=np.exp, check_inverse=False)\n",
    "\n",
    "numerical_features = ['temp','atemp','humidity','windspeed','day','hour']\n",
    "encode_column = ['season','workingday','weather','holiday','hour','year']\n",
    "\n",
    "numerical_pipeline = make_pipeline( logfunc, SimpleImputer(), MaxAbsScaler())\n",
    "encode_pipeline = make_pipeline(StandardScaler(), OneHotEncoder())\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n",
    "\n",
    "\n",
    "extratree = ExtraTreesRegressor( random_state=2)\n",
    "\n",
    "model_extratree = make_pipeline(preprocessor, ExtraTreesRegressor( random_state=2))\n",
    "model_extratree.fit(train_data_all_X , train_data_all_y)\n",
    "model_extratree.score(test_data_all_X, test_data_all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayoub/anaconda3/envs/envIA/lib/python3.10/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:25:53] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:25:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"subsample_freq\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayoub/anaconda3/envs/envIA/lib/python3.10/site-packages/pandas/core/internals/blocks.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = func(self.values, **kwargs)\n",
      "/home/ayoub/anaconda3/envs/envIA/lib/python3.10/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8935176959973627"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing et model Votingmodel : 0.9128708284712846 (1min50)\n",
    "\n",
    "logfunc = FunctionTransformer(func=np.log1p, inverse_func=np.exp, check_inverse=False)\n",
    "\n",
    "numerical_features = ['temp','atemp','humidity','windspeed','day','hour']\n",
    "encode_column = ['season','workingday','weather','holiday','hour','year']\n",
    "\n",
    "numerical_pipeline = make_pipeline( logfunc, SimpleImputer(), MaxAbsScaler())\n",
    "encode_pipeline = make_pipeline(StandardScaler(), OneHotEncoder())\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n",
    "\n",
    "VC = VotingRegressor([('xgboos' , xgboost), ('extratree' , model_lgbm), ('lgbm' , extratree)])\n",
    "\n",
    "model_extratree = make_pipeline(preprocessor, VC)\n",
    "\n",
    "VC.fit(train_data_all_X, train_data_all_y)\n",
    "VC.score(test_data_all_X, test_data_all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBRegressor' object has no attribute 'XGBEegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000027?line=10'>11</a>\u001b[0m other_pipeline \u001b[39m=\u001b[39m make_pipeline(OrdinalEncoder())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000027?line=12'>13</a>\u001b[0m preprocessor \u001b[39m=\u001b[39m make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000027?line=14'>15</a>\u001b[0m stack_model \u001b[39m=\u001b[39m StackingRegressor( (model_lgbm, VC) ,final_estimator\u001b[39m=\u001b[39mxgboost\u001b[39m.\u001b[39;49mXGBEegressor())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000027?line=16'>17</a>\u001b[0m model_extratree \u001b[39m=\u001b[39m make_pipeline(preprocessor, stack_model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayoub/Documents/projet/simplon/projet_bike/api_flask_bike/model/test_notebook.ipynb#ch0000027?line=18'>19</a>\u001b[0m model_extratree\u001b[39m.\u001b[39mfit(train_data_all_X, train_data_all_y)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBRegressor' object has no attribute 'XGBEegressor'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing et model Votingmodel : 0.9128708284712846 (1min50)\n",
    "\n",
    "logfunc = FunctionTransformer(func=np.log1p, inverse_func=np.exp, check_inverse=False)\n",
    "\n",
    "numerical_features = ['temp','atemp','humidity','windspeed','day','hour']\n",
    "encode_column = ['season','workingday','weather','holiday','hour','year']\n",
    "other_column = ['season','weather','holiday']\n",
    "\n",
    "numerical_pipeline = make_pipeline( logfunc, StandardScaler())\n",
    "encode_pipeline = make_pipeline(OneHotEncoder())\n",
    "other_pipeline = make_pipeline(OrdinalEncoder())\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features),(encode_pipeline , encode_column))\n",
    "\n",
    "stack_model = StackingRegressor( (model_lgbm, VC) ,final_estimator=VC)\n",
    "\n",
    "model_extratree = make_pipeline(preprocessor, stack_model)\n",
    "\n",
    "model_extratree.fit(train_data_all_X, train_data_all_y)\n",
    "model_extratree.score(test_data_all_X, test_data_all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,5,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a00c006436b821f608c703318a74ed0ce3a811dd7e5d1614f28a5307e338c8c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('api_work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
